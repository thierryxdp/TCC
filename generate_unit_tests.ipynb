{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "import inspect\n",
    "import openai\n",
    "import re\n",
    "import importlib\n",
    "import ast\n",
    "from IPython.display import Markdown, display\n",
    "from utils import *\n",
    "from utils_cfg import GeradorDeRequisitos, createControlFlowGraph\n",
    "from problems import getProblems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processo de Geração de Testes Unitarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    openai.api_key = \"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\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    start_time = time.time()\n",
    "    response = None\n",
    "    while time.time() - start_time < 90:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        if 'choices' in response and len(response['choices']) > 0:\n",
    "            return response['choices'][0]['message']['content']\n",
    "\n",
    "    return \"Request timed out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template_text(theme, context, final_tests, function_lines):\n",
    "    template_text = \"\"\n",
    "    template_text += \"Vou te passar testes em pytest para um problema de programação em python sobre o tema (\"\n",
    "    template_text += theme\n",
    "    template_text += \").\\nEm seguida te passarei o contexto do problema e a solução. Quero que você use os meus testes, aqueles que forneci, mas altere os parâmetros para valores que fazem sentido no problema dado, apenas valores que aparecem no problema real.\\n É muito importante que cada teste tenha somente um assert, se tiver mais de um assert é necessario botar em outro teste com nome do teste diferente.\\n\\n\"\n",
    "    template_text += \"Meus Testes:\\n\"\n",
    "    for test in final_tests:\n",
    "        template_text += test\n",
    "    template_text += \"\\n\\nContexto do Problema:\\n\"\n",
    "    template_text += context + \"\\n\\nSolução do problema em python:\\n\"\n",
    "    for line in function_lines:\n",
    "        template_text += line + \"\\n\"\n",
    "\n",
    "    template_text += \"\\n\\nÉ MUITO IMPORTANTE que a quantidade de testes se mantenha. Só é válido adicionar mais testes se eles percorrem caminhos de execução diferentes!! Por fim, ponha os testes neste formato:\\n\"\n",
    "    template_text += \"def test_1():\\n   assert...\\n\\n\"\n",
    "    template_text += \"def test_2():\\n   assert...\\n\\n\"\n",
    "    template_text += \"def test_3():\\n   assert...\\n\\n\"\n",
    "    \n",
    "    return template_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_tests_from_response(gpt_response):\n",
    "    gpt_tests = []\n",
    "    current_test = \"\"\n",
    "    test_start = False\n",
    "    gpt_response += \"\\n\"\n",
    "    lines = gpt_response.split('\\n')\n",
    "    for line in lines:\n",
    "        if \"def\" in line and \"test\" in line:\n",
    "            test_start = True\n",
    "        if (len(line) == 0 and len(current_test) > 0):\n",
    "            gpt_tests.append(current_test)\n",
    "            current_test = \"\"\n",
    "            test_start = False\n",
    "        if (test_start):\n",
    "            current_test += line + \"\\n\"\n",
    "    \n",
    "    return gpt_tests[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_test(test_string, module_name):\n",
    "    parts = test_string.split(\" == \")\n",
    "    if len(parts) != 2:\n",
    "        return \"Invalid test format.\"\n",
    "\n",
    "    function_call, expected_result = parts\n",
    "    if \"(\" in function_call and \")\" in function_call:\n",
    "        function_name, arg_str = function_call.split(\"(\", 1)\n",
    "        args = eval(\"[\" + arg_str[:-1] + \"]\")\n",
    "    else:\n",
    "        return \"Invalid function call format.\"\n",
    "\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        function = getattr(module, function_name)\n",
    "        result = function(*args)\n",
    "\n",
    "        if result == eval(expected_result):\n",
    "            return f\"Test passed: {test_string}\"\n",
    "        else:\n",
    "            return f\"Test failed: {test_string}\"\n",
    "    except ImportError:\n",
    "        return f\"Module '{module_name}' not found.\"\n",
    "    except AttributeError:\n",
    "        return f\"Function '{function_name}' not found in module '{module_name}'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_commas(string: str) -> str:\n",
    "    return string.replace('\"', '\\\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_gpt_tests(gpt_tests, function_lines):\n",
    "    file_name = getMethodName(function_lines) + \".py\"\n",
    "    loop_blank_spaces, loop_commands = [], []\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"import re\" + \"\\n\")\n",
    "        file.write(\"import inspect\" + \"\\n\")\n",
    "        file.write(\"from typing import List\\n\")\n",
    "        file.write(function_lines[0] + \"\\n\")\n",
    "        file.write(\" \" * 4 + \"with open(\\\"holder.txt\\\", \\\"a\\\", encoding='utf-8') as file:\" + \"\\n\")\n",
    "        file.write(\" \" * 8 + \"file.write(\\\"\" + function_lines[0].strip().replace(\"def \", \"enter: \").replace(\"):\", \")\") + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "        for i in range(1, len(function_lines)):\n",
    "            if (count_blank_spaces(function_lines[i]) in loop_blank_spaces):\n",
    "                index = loop_blank_spaces.index(count_blank_spaces(function_lines[i]))\n",
    "                file.write(\" \" * 4 + \" \" * count_blank_spaces(loop_commands[index]) + \"file.write(\\\"\" + replace_commas(loop_commands[index].strip()) + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\") \n",
    "            if not \"else\" in function_lines[i]:\n",
    "                file.write(\" \" * 4 + \" \" * count_blank_spaces(function_lines[i]) + \"file.write(\\\"\" + replace_commas(function_lines[i].strip()) + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "            if \"return\" in function_lines[i]:\n",
    "                file.write(\" \" * 4 + \" \" * count_blank_spaces(function_lines[i]) + \"file.write(\\\"\" + replace_commas(function_lines[0].strip().replace(\"def \", \"exit: \").replace(\"):\", \")\")) + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "            file.write(\" \" * 4 + function_lines[i] + \"\\n\")\n",
    "            if \"for\" in function_lines[i] or \"while\" in function_lines[i]:\n",
    "                file.write(\" \" * 8 + \" \" * count_blank_spaces(function_lines[i]) + \"file.write(\\\"\" + replace_commas(function_lines[i].strip()) + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "                loop_blank_spaces.append(count_blank_spaces(function_lines[i]))\n",
    "                loop_commands.append(function_lines[i])\n",
    "            if \"else\" in function_lines[i]:\n",
    "                file.write(\" \" * 8 + \" \" * count_blank_spaces(function_lines[i]) + \"file.write(\\\"\" + replace_commas(function_lines[i].strip()) + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "\n",
    "    module = importlib.import_module(file_name.split(\".\")[0])\n",
    "    getattr(module, getMethodName(function_lines), None)\n",
    "\n",
    "    tests = []\n",
    "    for line in gpt_tests:\n",
    "        pattern = r'assert (.*)'\n",
    "        match = re.search(pattern, line)\n",
    "        if match:\n",
    "            matched_content = match.group(1)\n",
    "            tests.append(matched_content)\n",
    "\n",
    "    for test in tests:\n",
    "        execute_test(test, file_name.split(\".\")[0])\n",
    "        with open(\"holder.txt\", \"a\", encoding='utf-8') as file:\n",
    "            file.write(\"test_delimiter\\n\")\n",
    "\n",
    "    result, current_list = [], []\n",
    "    with open(\"holder.txt\", \"r\", encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"test_delimiter\":\n",
    "                if current_list:\n",
    "                    result.append(current_list)\n",
    "                current_list = []\n",
    "            else:\n",
    "                current_list.append(line)\n",
    "\n",
    "    if current_list:\n",
    "        result.append(current_list)\n",
    "\n",
    "    remove_file(file_name)\n",
    "    remove_all_files(\"__pycache__\")\n",
    "    remove_file(\"holder.txt\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crosshair_tests(function_lines):\n",
    "    file_name = \"solution.py\"\n",
    "\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"import inspect\\n\")\n",
    "        file.write(\"import re\\n\")\n",
    "        file.write(\"from typing import List\\n\")\n",
    "        for line in function_lines:\n",
    "            file.write(line + \"\\n\")\n",
    "\n",
    "    #tests = !crosshair cover --example_output_format=pytest --coverage_type=path solution.{getMethodName(function_lines)} --per_condition_timeout=200\n",
    "    tests = !crosshair cover --example_output_format=pytest --coverage_type=path solution.{getMethodName(function_lines)} --per_condition_timeout=100\n",
    "    remove_file(file_name)\n",
    "    \n",
    "    start_index = 0\n",
    "    for i in range(0, len(tests)):\n",
    "        if ('def' in tests[i]):\n",
    "            start_index = i\n",
    "            break\n",
    "\n",
    "    realtests = []\n",
    "    current_test = tests[start_index]\n",
    "    for i in range(start_index + 1, len(tests)):\n",
    "        if 'test_' in tests[i]:\n",
    "            realtests.append(current_test)\n",
    "            current_test = tests[i]\n",
    "        else:\n",
    "            current_test += \"\\n\" + tests[i] \n",
    "\n",
    "    final_tests = []\n",
    "    for rt in realtests:\n",
    "        if 'pytest.raises' not in rt and \"None\" not in rt:\n",
    "            final_tests.append(rt)\n",
    "\n",
    "    return final_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minimal_tests(nodes, test_nodes):\n",
    "    covered_nodes = set()\n",
    "    minimal_tests = []\n",
    "    sorted_test_nodes = sorted(test_nodes, key=len, reverse=True)\n",
    "\n",
    "    for i in range(len(sorted_test_nodes)):\n",
    "        uncovered_nodes = [node for node in sorted_test_nodes[i] if node not in covered_nodes]\n",
    "        \n",
    "        if len(uncovered_nodes) > 0:\n",
    "            minimal_tests.append(sorted_test_nodes[i])\n",
    "            covered_nodes.update(uncovered_nodes)\n",
    "\n",
    "        if len(covered_nodes) == len(nodes):\n",
    "            break\n",
    "\n",
    "    return minimal_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class CoverageCriteria(Enum):\n",
    "    NONE = 0\n",
    "    NODES = 1\n",
    "    EDGES = 2\n",
    "    PAIR_EDGES = 3\n",
    "\n",
    "def filter_tests(result, criteria, gpt_tests):\n",
    "    filename = \"problem_solution\"\n",
    "    nodes = GeradorDeRequisitos(\"./\"+filename+\".py\", filename)\n",
    "    all, tests = [], []\n",
    "\n",
    "    for test in result:\n",
    "        tests_n = []\n",
    "        for line in test:\n",
    "            for n in nodes:\n",
    "                if line.replace('\\n', '').replace(' ', '') in n[2].replace('\\n', '').replace(' ', ''):\n",
    "                    tests_n.append(n[0])\n",
    "        tests.append(remove_adjacent_duplicates(tests_n))\n",
    "\n",
    "    if criteria == CoverageCriteria.NODES:\n",
    "        all = [sublist[0] for sublist in nodes]\n",
    "    elif criteria == CoverageCriteria.EDGES:\n",
    "        if len(nodes) <= 1:\n",
    "            all = [sublist[0] for sublist in nodes]\n",
    "        else:\n",
    "            for node in nodes:\n",
    "                    for idx, neighbour in enumerate(node[1]):\n",
    "                        all.append(tuple([node[0],node[1][idx]]))\n",
    "\n",
    "            test_edges, current_test_edges = [], []\n",
    "            for test in tests:\n",
    "                for i in range(len(test) - 1):\n",
    "                    current_test_edges.append(tuple([test[i], test[i+1]]))\n",
    "                test_edges.append(current_test_edges)\n",
    "                current_test_edges = []\n",
    "            tests = test_edges\n",
    "    elif criteria == CoverageCriteria.PAIR_EDGES:\n",
    "        if len(nodes) <= 1:\n",
    "            all = [sublist[0] for sublist in nodes]\n",
    "        else:\n",
    "            all_pairs, tests_pair_edges = [], []\n",
    "            with open(\"requisitos \" + filename + \".txt\", \"r\") as file:\n",
    "                for line in file:\n",
    "                    if \"par de arcos\" in line:\n",
    "                        all_pairs = ast.literal_eval(line[line.index(\":\") + 1:].strip())\n",
    "            for tn in tests:\n",
    "                pairs, current_pair, unique_pairs, test_pair_edge = [], [], [], []\n",
    "                for node in tn:\n",
    "                    current_pair.append(node)\n",
    "                    if (len(current_pair) == 3):\n",
    "                        pairs.append(current_pair)\n",
    "                        current_pair = current_pair[1:]\n",
    "                \n",
    "                if (len(current_pair) < 3 and len(pairs) == 0):\n",
    "                    pairs.append(current_pair)\n",
    "\n",
    "                for sublist in pairs:\n",
    "                    if sublist not in unique_pairs:\n",
    "                        unique_pairs.append(sublist)\n",
    "\n",
    "                for sublist in unique_pairs:\n",
    "                    test_pair_edge.append(tuple(sublist))\n",
    "\n",
    "                tests_pair_edges.append(test_pair_edge)\n",
    "\n",
    "            all_pairs_tuples = []\n",
    "            for sublist in all_pairs:\n",
    "                all_pairs_tuples.append(tuple(sublist))\n",
    "\n",
    "            all = all_pairs_tuples\n",
    "            tests = tests_pair_edges\n",
    "    else:\n",
    "        print(\"Coverage Criteria not found.\")\n",
    "\n",
    "    print(len(all), 'Requisitos a satisfazer: ', all, '\\n')\n",
    "    minimal_tests = find_minimal_tests(all, tests)\n",
    "    \n",
    "    filtered_list = []\n",
    "    for minimal_test in minimal_tests:\n",
    "        filtered_test = gpt_tests[tests.index(minimal_test)]\n",
    "        satisfied_tests = list(set(minimal_test))\n",
    "        print('Requisitos satisfeitos pelo teste:', satisfied_tests, '->', str(len(satisfied_tests)) + '/' + str(len(all)))\n",
    "        print(filtered_test)\n",
    "        filtered_list.append(filtered_test)\n",
    "        \n",
    "    remove_file('requisitos problem_solution.txt')\n",
    "    \n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tests_results(crosshair_tests, result, function_lines, criteria, context, theme):\n",
    "    display(Markdown(f\"<font color=magenta>Testes CrossHair Filtrados</font>\"))\n",
    "    filtered_crosshair_tests = filter_tests(result, criteria, crosshair_tests)\n",
    "    display(Markdown(f\"<font color=magenta>Testes ChatGpt</font>\"))\n",
    "    template_text = get_template_text(theme, context, filtered_crosshair_tests, function_lines)\n",
    "    gpt_response = get_completion(template_text)\n",
    "    gpt_tests = get_gpt_tests_from_response(gpt_response)\n",
    "    for t in gpt_tests:\n",
    "        print(t)\n",
    "    display(Markdown(f\"<font color=magenta>Testes ChatGpt Filtrados</font>\"))\n",
    "    result = validate_gpt_tests(gpt_tests, function_lines)\n",
    "    with open(\"problem_solution.py\", 'w') as file:\n",
    "        for line in function_lines:\n",
    "            file.write(line + \"\\n\")\n",
    "    filter_tests(result, criteria, gpt_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_re_usage(function_lines):\n",
    "    new_function_lines = []\n",
    "    i = 0\n",
    "    while i < len(function_lines):\n",
    "        if 're.fullmatch' in function_lines[i]:\n",
    "            i += 2\n",
    "        else:\n",
    "            new_function_lines.append(function_lines[i])\n",
    "            i += 1\n",
    "        \n",
    "    return new_function_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unit_tests(function_lines, context, theme):\n",
    "    crosshair_tests = get_crosshair_tests(function_lines)\n",
    "    function_lines = remove_re_usage(function_lines)\n",
    "    print('Function Lines\\n', function_lines)\n",
    "    result = validate_gpt_tests(crosshair_tests, function_lines)\n",
    "    with open(\"problem_solution.py\", 'w') as file:\n",
    "        for line in function_lines:\n",
    "            file.write(line + \"\\n\")\n",
    "            \n",
    "    display(Markdown(f\"<font color=yellow>Grafo de fluxo de controle do problema:</font>\"))\n",
    "    createControlFlowGraph()\n",
    "    \n",
    "    display(Markdown(f\"<font color=yellow>Testes Critério de Nós</font>\"))\n",
    "    get_tests_results(crosshair_tests, result, function_lines, CoverageCriteria.NODES, context, theme)\n",
    "    \n",
    "    display(Markdown(f\"<font color=yellow>Testes Critério de Arestas</font>\"))\n",
    "    get_tests_results(crosshair_tests, result, function_lines, CoverageCriteria.EDGES, context, theme)\n",
    "\n",
    "    display(Markdown(f\"<font color=yellow>Testes Critério de Par de Arestas</font>\"))\n",
    "    get_tests_results(crosshair_tests, result, function_lines, CoverageCriteria.PAIR_EDGES, context, theme)\n",
    "    \n",
    "    remove_file(\"problem_solution.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Lines\n",
      " ['def freq_palavras(frase: str) -> dict:', '    dic = {}', '    lista = frase.split()', '    for palavra in lista:', '        if palavra in dic:', '            dic[palavra] += 1', '        else:', '            dic[palavra] = 1', '    return dic', '']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=yellow>Grafo de fluxo de controle do problema:</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"477pt\" height=\"280pt\"\n",
       " viewBox=\"0.00 0.00 477.03 279.86\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 275.86)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-275.86 473.03,-275.86 473.03,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"208.03\" cy=\"-243.93\" rx=\"82.38\" ry=\"27.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"208.03\" y=\"-246.38\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0 : dic = {}</text>\n",
       "<text text-anchor=\"middle\" x=\"208.03\" y=\"-230.63\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lista = frase.split()</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"orange\" points=\"305.43,-154.54 305.43,-169.46 248.37,-180 167.68,-180 110.63,-169.46 110.63,-154.54 167.68,-144 248.37,-144 305.43,-154.54\"/>\n",
       "<text text-anchor=\"middle\" x=\"208.03\" y=\"-156.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1 : for palavra in lista:</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.03,-215.87C208.03,-208.05 208.03,-199.49 208.03,-191.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"211.53,-191.77 208.03,-181.77 204.53,-191.77 211.53,-191.77\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"red\" points=\"317.03,-108 202.47,-90 317.03,-72 431.58,-90 317.03,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"317.03\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2 : if palavra in dic:</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M235.25,-143.52C250.6,-133.66 269.85,-121.3 285.81,-111.05\"/>\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"287.46,-114.15 293.99,-105.8 283.68,-108.26 287.46,-114.15\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"green\" points=\"184.41,-108 50.18,-108 15.65,-72 149.88,-72 184.41,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.03\" y=\"-84.58\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3 : return dic</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M181.05,-143.52C167.42,-134.68 150.69,-123.84 135.98,-114.3\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"138.22,-111.59 127.93,-109.08 134.42,-117.46 138.22,-111.59\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"131.03\" cy=\"-18\" rx=\"86.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"131.03\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4 : dic[palavra] += 1</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M284.63,-76.81C256.39,-66.18 214.94,-50.58 182.22,-38.27\"/>\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"183.49,-35.01 172.9,-34.76 181.03,-41.56 183.49,-35.01\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"388.03\" cy=\"-18\" rx=\"81\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"388.03\" y=\"-12.57\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">5 : dic[palavra] = 1</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M332.08,-74.15C341.01,-65.35 352.56,-53.97 362.84,-43.83\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"365,-46.62 369.67,-37.1 360.09,-41.63 365,-46.62\"/>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.93,-30.72C44.75,-38.4 20.83,-51.09 7.03,-72 -1.79,-85.35 -2.74,-95.33 7.03,-108 21.22,-126.43 72.09,-139.73 119.1,-148.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.36,-151.83 128.82,-150.14 119.59,-144.94 118.36,-151.83\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M409.98,-35.61C431.84,-54.17 459.65,-84.67 441.03,-108 423.99,-129.35 362.83,-142.76 307.45,-150.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"307.03,-147.27 297.6,-152.11 307.99,-154.2 307.03,-147.27\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1e4ae083580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=yellow>Testes Critério de Nós</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=magenta>Testes CrossHair Filtrados</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Requisitos a satisfazer:  [0, 1, 2, 3, 4, 5] \n",
      "\n",
      "Requisitos satisfeitos pelo teste: [0, 1, 2, 3, 4, 5] -> 6/6\n",
      "def test_freq_palavras():\n",
      "    assert freq_palavras('another another') == {'another': 2}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=magenta>Testes ChatGpt</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test_freq_palavras():\n",
      "    assert freq_palavras('dinheiro é dinheiro e vice versa') == {'dinheiro': 2, 'é': 1, 'e': 1, 'vice': 1, 'versa': 1}\n",
      "\n",
      "def test_freq_palavras_vazia():\n",
      "    assert freq_palavras('') == {}\n",
      "\n",
      "def test_freq_palavras_uma_palavra():\n",
      "    assert freq_palavras('python') == {'python': 1}\n",
      "\n",
      "def test_freq_palavras_palavras_repetidas():\n",
      "    assert freq_palavras('teste teste teste') == {'teste': 3}\n",
      "\n",
      "def test_freq_palavras_palavras_com_maiusculas():\n",
      "    assert freq_palavras('Python é uma linguagem de programação Python') == {'Python': 2, 'é': 1, 'uma': 1, 'linguagem': 1, 'de': 1, 'programação': 1}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=magenta>Testes ChatGpt Filtrados</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Requisitos a satisfazer:  [0, 1, 2, 3, 4, 5] \n",
      "\n",
      "Requisitos satisfeitos pelo teste: [0, 1, 2, 3, 4, 5] -> 6/6\n",
      "def test_freq_palavras_palavras_com_maiusculas():\n",
      "    assert freq_palavras('Python é uma linguagem de programação Python') == {'Python': 2, 'é': 1, 'uma': 1, 'linguagem': 1, 'de': 1, 'programação': 1}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=yellow>Testes Critério de Arestas</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=magenta>Testes CrossHair Filtrados</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Requisitos a satisfazer:  [(0, 1), (1, 2), (1, 3), (2, 4), (2, 5), (4, 1), (5, 1)] \n",
      "\n",
      "Requisitos satisfeitos pelo teste: [(0, 1), (1, 3), (2, 4), (1, 2), (5, 1), (2, 5), (4, 1)] -> 7/7\n",
      "def test_freq_palavras():\n",
      "    assert freq_palavras('another another') == {'another': 2}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=magenta>Testes ChatGpt</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test_freq_palavras():\n",
      "    assert freq_palavras('dinheiro é dinheiro e vice versa') == {'dinheiro': 2, 'é': 1, 'e': 1, 'vice': 1, 'versa': 1}\n",
      "\n",
      "def test_freq_palavras_vazia():\n",
      "    assert freq_palavras('') == {}\n",
      "\n",
      "def test_freq_palavras_uma_palavra():\n",
      "    assert freq_palavras('python') == {'python': 1}\n",
      "\n",
      "def test_freq_palavras_palavras_repetidas():\n",
      "    assert freq_palavras('teste teste teste') == {'teste': 3}\n",
      "\n",
      "def test_freq_palavras_palavras_com_pontuacao():\n",
      "    assert freq_palavras('python, é uma linguagem de programação.') == {'python,': 1, 'é': 1, 'uma': 1, 'linguagem': 1, 'de': 1, 'programação.': 1}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=magenta>Testes ChatGpt Filtrados</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Requisitos a satisfazer:  [(0, 1), (1, 2), (1, 3), (2, 4), (2, 5), (4, 1), (5, 1)] \n",
      "\n",
      "Requisitos satisfeitos pelo teste: [(0, 1), (1, 3), (2, 4), (1, 2), (5, 1), (2, 5), (4, 1)] -> 7/7\n",
      "def test_freq_palavras():\n",
      "    assert freq_palavras('dinheiro é dinheiro e vice versa') == {'dinheiro': 2, 'é': 1, 'e': 1, 'vice': 1, 'versa': 1}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=yellow>Testes Critério de Par de Arestas</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<font color=magenta>Testes CrossHair Filtrados</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Requisitos a satisfazer:  [(0, 1, 2), (0, 1, 3), (1, 2, 4), (1, 2, 5), (2, 4, 1), (2, 5, 1), (4, 1, 2), (4, 1, 3), (5, 1, 2), (5, 1, 3)] \n",
      "\n",
      "Requisitos satisfeitos pelo teste: [(5, 1, 2), (2, 4, 1), (2, 5, 1), (1, 2, 5), (4, 1, 3), (0, 1, 2), (1, 2, 4)] -> 7/10\n",
      "def test_freq_palavras():\n",
      "    assert freq_palavras('another another') == {'another': 2}\n",
      "\n",
      "Requisitos satisfeitos pelo teste: [(5, 1, 2), (2, 5, 1), (1, 2, 5), (0, 1, 2), (5, 1, 3)] -> 5/10\n",
      "def test_freq_palavras_405():\n",
      "    assert freq_palavras('another value') == {'another': 1, 'value': 1}\n",
      "\n",
      "Requisitos satisfeitos pelo teste: [(0, 1, 3)] -> 1/10\n",
      "def test_freq_palavras_9():\n",
      "    assert freq_palavras('') == {}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=magenta>Testes ChatGpt</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test_freq_palavras():\n",
      "    assert freq_palavras('dinheiro é dinheiro e vice versa') == {'dinheiro': 2, 'é': 1, 'e': 1, 'vice': 1, 'versa': 1}\n",
      "\n",
      "def test_freq_palavras_405():\n",
      "    assert freq_palavras('dinheiro é valor') == {'dinheiro': 1, 'é': 1, 'valor': 1}\n",
      "\n",
      "def test_freq_palavras_9():\n",
      "    assert freq_palavras('') == {}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color=magenta>Testes ChatGpt Filtrados</font>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Requisitos a satisfazer:  [(0, 1, 2), (0, 1, 3), (1, 2, 4), (1, 2, 5), (2, 4, 1), (2, 5, 1), (4, 1, 2), (4, 1, 3), (5, 1, 2), (5, 1, 3)] \n",
      "\n",
      "Requisitos satisfeitos pelo teste: [(5, 1, 2), (2, 4, 1), (2, 5, 1), (4, 1, 2), (1, 2, 5), (0, 1, 2), (5, 1, 3), (1, 2, 4)] -> 8/10\n",
      "def test_freq_palavras():\n",
      "    assert freq_palavras('dinheiro é dinheiro e vice versa') == {'dinheiro': 2, 'é': 1, 'e': 1, 'vice': 1, 'versa': 1}\n",
      "\n",
      "Requisitos satisfeitos pelo teste: [(0, 1, 3)] -> 1/10\n",
      "def test_freq_palavras_9():\n",
      "    assert freq_palavras('') == {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "problems = getProblems()\n",
    "\n",
    "for problem in problems:\n",
    "    generate_unit_tests(problem[0].split('\\n'), problem[1], problem[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
