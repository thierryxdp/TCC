{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.28.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\thier\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests>=2.20->openai) (2022.9.24)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: pytest in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (7.4.2)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pytest) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pytest) (21.3)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pytest) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pytest) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pytest) (1.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pytest) (0.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\thier\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from packaging->pytest) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\thier\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "import openai\n",
    "import pytest\n",
    "from py2cfg import CFGBuilder\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processo de Geração de Testes Unitarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    openai.api_key = \"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\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template_text(theme, context, final_tests, function_lines):\n",
    "    template_text = \"\"\n",
    "    template_text += \"Vou te passar testes em pytest para um problema de programação em python sobre o tema (\"\n",
    "    template_text += theme\n",
    "    template_text += \").\\nEm seguida te passarei o contexto do problema e a solução. Quero que você use os meus testes, aqueles que forneci, mas altere TODOS os parâmetros para valores que fazem sentido no problema dado, apenas valores que aparecem no problema real.\\nNo final, refaça os testes redundantes, ou seja, se um teste tiver a mesma entrada e a mesma saída que outro teste, altere os valores de um dos testes. É muito importante que cada teste tenha somente um assert, se tiver mais de um assert é necessario botar em outro teste com nome do teste diferente.\\n\\n\"\n",
    "    template_text += \"Meus Testes:\\n\"\n",
    "    for test in final_tests:\n",
    "        template_text += test\n",
    "    template_text += \"\\n\\nContexto do Problema:\\n\"\n",
    "    template_text += context + \"\\n\\nSolução do problema em python:\\n\"\n",
    "    for line in function_lines:\n",
    "        template_text += line + \"\\n\"\n",
    "\n",
    "    template_text += \"\\n\\nPor fim, ponha os testes neste formato:\\n\"\n",
    "    template_text += \"def test_1():\\n   assert...\\n\\n\"\n",
    "    template_text += \"def test_2():\\n   assert...\\n\\n\"\n",
    "    template_text += \"def test_3():\\n   assert...\\n\\n\"\n",
    "    \n",
    "    return template_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_file(file_name):\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_files(folder):\n",
    "    # Verify that the folder exists\n",
    "    if os.path.exists(folder):\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(folder)\n",
    "        # Iterate over the files and remove them one by one\n",
    "        for file in files:\n",
    "            file_path = os.path.join(folder, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    #print(f\"Removed: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing {file_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Folder not found: {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_tests_from_response(gpt_response):\n",
    "    gpt_tests = []\n",
    "    current_test = \"\"\n",
    "    test_start = False\n",
    "    gpt_response += \"\\n\"\n",
    "    lines = gpt_response.split('\\n')\n",
    "    for line in lines:\n",
    "        if \"def\" in line:\n",
    "            test_start = True\n",
    "        if (len(line) == 0 and len(current_test) > 0):\n",
    "            gpt_tests.append(current_test)\n",
    "            current_test = \"\"\n",
    "            test_start = False\n",
    "        if (test_start):\n",
    "            current_test += line + \"\\n\"\n",
    "    \n",
    "    print(\"Testes:\")\n",
    "    for test in gpt_tests:\n",
    "            for line in test.split('\\n'):\n",
    "                print(line)\n",
    "\n",
    "    return gpt_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_blank_spaces(input_string):\n",
    "    count = 0\n",
    "    for char in input_string:\n",
    "        if char.isspace():\n",
    "            count += 1\n",
    "        else:\n",
    "            break  # Exit the loop when a non-blank space character is encountered\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_gpt_tests(gpt_tests, function_lines):\n",
    "    print(gpt_tests)\n",
    "    print(function_lines)\n",
    "    file_name = \"run_generated_tests.py\"\n",
    "\n",
    "    with open(file_name, 'w') as file:\n",
    "        file.write(\"import inspect\" + \"\\n\\n\")\n",
    "        file.write(function_lines[0] + \"\\n\")\n",
    "        file.write(\" \" * 4 + \"with open(\\\"holder.txt\\\", \\\"a+\\\") as file:\" + \"\\n\")\n",
    "        for i in range(1, len(function_lines)):\n",
    "            file.write(\" \" * 4 + \" \" * count_blank_spaces(function_lines[i]) + \"file.write(str(inspect.currentframe().f_lineno - \" + str(i + 2) + \") + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "            file.write(\" \" * 4 + function_lines[i] + \"\\n\")\n",
    "\n",
    "        file.write(\"\\n\")\n",
    "        for test in gpt_tests:\n",
    "            for line in test.split('\\n'):\n",
    "                file.write(line + \"\\n\")\n",
    "\n",
    "    exit_code = pytest.main([\"-qq\", \"run_generated_tests.py\"])\n",
    "    if exit_code == 0:\n",
    "        print(\"All tests passed!\")\n",
    "    else:\n",
    "        print(\"Some tests failed.\")\n",
    "\n",
    "    remove_file(file_name)\n",
    "    remove_all_files(\"__pycache__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crosshair_tests(function_lines):\n",
    "    file_name = \"solution.py\"\n",
    "\n",
    "    with open(file_name, 'w') as file:\n",
    "        # Write text to the file\n",
    "        for line in function_lines:\n",
    "            file.write(line + \"\\n\")\n",
    "    \n",
    "    tests = !crosshair cover --example_output_format=pytest --coverage_type=path solution.intercala --per_condition_timeout=100\n",
    "\n",
    "    remove_file(file_name)\n",
    "\n",
    "    realtests = []\n",
    "    current_test = tests[3]\n",
    "    for i in range(4, len(tests)):\n",
    "        if 'test_' in tests[i]:\n",
    "            realtests.append(current_test)\n",
    "            current_test = tests[i]\n",
    "        else:\n",
    "            current_test += \"\\n\" + tests[i] \n",
    "\n",
    "    final_tests = []\n",
    "    for rt in realtests:\n",
    "        if 'pytest.raises' not in rt:\n",
    "            final_tests.append(rt)\n",
    "    \n",
    "    return final_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unit_tests(solution, context, theme):\n",
    "    function_lines = inspect.getsource(solution).splitlines()\n",
    "    crosshair_tests = get_crosshair_tests(function_lines)\n",
    "    template_text = get_template_text(theme, context, crosshair_tests, function_lines)\n",
    "    gpt_response = get_completion(template_text)\n",
    "    gpt_tests = get_gpt_tests_from_response(gpt_response)\n",
    "    validate_gpt_tests(gpt_tests, function_lines)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testes:\n",
      "def test_intercala():\n",
      "    assert intercala([1, 3, 5], [2, 4, 6]) == [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "def test_intercala_2():\n",
      "    assert intercala([7, 9, 11], [8, 10, 12]) == [7, 8, 9, 10, 11, 12]\n",
      "\n",
      "def test_intercala_3():\n",
      "    assert intercala([0, 2, 4], [1, 3, 5]) == [0, 1, 2, 3, 4, 5]\n",
      "\n",
      "['def test_intercala():\\n    assert intercala([1, 3, 5], [2, 4, 6]) == [1, 2, 3, 4, 5, 6]\\n', 'def test_intercala_2():\\n    assert intercala([7, 9, 11], [8, 10, 12]) == [7, 8, 9, 10, 11, 12]\\n', 'def test_intercala_3():\\n    assert intercala([0, 2, 4], [1, 3, 5]) == [0, 1, 2, 3, 4, 5]\\n']\n",
      "['def intercala(lista1,lista2):', '    lista3 = 6*[0]', '    lista3[::2] = lista1', '    lista3[1::2] = lista2', '    return lista3']\n",
      ".                                                                        [100%]\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def intercala(lista1,lista2):\n",
    "    lista3 = 6*[0]\n",
    "    lista3[::2] = lista1\n",
    "    lista3[1::2] = lista2\n",
    "    return lista3\n",
    "\n",
    "context = '''Faça uma função chamada definida por **\\`intercala(lista1, lista2)\\`** que dadas duas listas L1 e L2 de tamanho 3, gera uma lista L3 que é formada intercalando os elementos de L1 e L2. \n",
    "\n",
    "\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "L1 = [1, 3, 5] e L2 = [2, 4, 6] gera L3 = [1, 2, 3, 4, 5, 6].'''\n",
    "\n",
    "theme = \"Listas e Dicionários\"\n",
    "\n",
    "generate_unit_tests(intercala, context, theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testes:\n",
      "def test_1():\n",
      "    assert freq_palavras(\"dinheiro é dinheiro e vice versa\") == {\"dinheiro\": 2, \"é\": 1, \"e\": 1, \"vice\": 1, \"versa\": 1}\n",
      "\n",
      "def test_2():\n",
      "    assert freq_palavras(\"o rato roeu a roupa do rei de roma\") == {\"o\": 2, \"rato\": 1, \"roeu\": 1, \"a\": 1, \"roupa\": 1, \"do\": 1, \"rei\": 1, \"de\": 1, \"roma\": 1}\n",
      "\n",
      "def test_3():\n",
      "    assert freq_palavras(\"a vida é bela\") == {\"a\": 1, \"vida\": 1, \"é\": 1, \"bela\": 1}\n",
      "\n",
      "def test_4():\n",
      "    assert freq_palavras(\"python é uma linguagem de programação\") == {\"python\": 1, \"é\": 1, \"uma\": 1, \"linguagem\": 1, \"de\": 1, \"programação\": 1}\n",
      "\n",
      "def test_5():\n",
      "    assert freq_palavras(\"o sol nasce para todos\") == {\"o\": 1, \"sol\": 1, \"nasce\": 1, \"para\": 1, \"todos\": 1}\n",
      "\n",
      "['def test_1():\\n    assert freq_palavras(\"dinheiro é dinheiro e vice versa\") == {\"dinheiro\": 2, \"é\": 1, \"e\": 1, \"vice\": 1, \"versa\": 1}\\n', 'def test_2():\\n    assert freq_palavras(\"o rato roeu a roupa do rei de roma\") == {\"o\": 2, \"rato\": 1, \"roeu\": 1, \"a\": 1, \"roupa\": 1, \"do\": 1, \"rei\": 1, \"de\": 1, \"roma\": 1}\\n', 'def test_3():\\n    assert freq_palavras(\"a vida é bela\") == {\"a\": 1, \"vida\": 1, \"é\": 1, \"bela\": 1}\\n', 'def test_4():\\n    assert freq_palavras(\"python é uma linguagem de programação\") == {\"python\": 1, \"é\": 1, \"uma\": 1, \"linguagem\": 1, \"de\": 1, \"programação\": 1}\\n', 'def test_5():\\n    assert freq_palavras(\"o sol nasce para todos\") == {\"o\": 1, \"sol\": 1, \"nasce\": 1, \"para\": 1, \"todos\": 1}\\n']\n",
      "['def freq_palavras(frase):', '    dic = {}', '    lista = frase.split()', '    for palavra in lista:', '        if palavra in dic:', '            dic[palavra] += 1', '        else:', '            dic[palavra] = 1', '    return dic']\n",
      ".                                                                        [100%]\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def freq_palavras(frase):\n",
    "    dic = {}\n",
    "    lista = frase.split()\n",
    "    for palavra in lista:\n",
    "        if palavra in dic:\n",
    "            dic[palavra] += 1\n",
    "        else:\n",
    "            dic[palavra] = 1\n",
    "    return dic\n",
    "\n",
    "context = '''Construa uma função chamada **freq_palavras(frases)** que receba uma string e retorne um dicionário onde cada palavra dessa string seja uma chave e tenha como valor o número de vezes que a palavra aparece. Por exemplo: \n",
    "\n",
    "- freq_palavras(\"dinheiro é dinheiro e vice versa\") \n",
    "\n",
    "Retorna o dicionário: { \"dinheiro\":2, \"é\": 1, \"e\": 1, \"vice\": 1, \"versa\":1}'''\n",
    "\n",
    "theme = \"Estrutura de repetição iteradora: for\"\n",
    "\n",
    "generate_unit_tests(freq_palavras, context, theme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtro de Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"run_generated_tests.py\"\n",
    "\n",
    "gpt_tests = ['def test_1():\\n    assert freq_palavras(\"dinheiro é dinheiro e vice versa\") == {\"dinheiro\": 2, \"é\": 1, \"e\": 1, \"vice\": 1, \"versa\": 1}\\n', 'def test_2():\\n    assert freq_palavras(\"o rato roeu a roupa do rei de roma\") == {\"o\": 2, \"rato\": 1, \"roeu\": 1, \"a\": 1, \"roupa\": 1, \"do\": 1, \"rei\": 1, \"de\": 1, \"roma\": 1}\\n', 'def test_3():\\n    assert freq_palavras(\"a vida é bela\") == {\"a\": 1, \"vida\": 1, \"é\": 1, \"bela\": 1}\\n', 'def test_4():\\n    assert freq_palavras(\"python é uma linguagem de programação\") == {\"python\": 1, \"é\": 1, \"uma\": 1, \"linguagem\": 1, \"de\": 1, \"programação\": 1}\\n', 'def test_5():\\n    assert freq_palavras(\"o sol nasce para todos\") == {\"o\": 1, \"sol\": 1, \"nasce\": 1, \"para\": 1, \"todos\": 1}\\n']\n",
    "function_lines = ['def freq_palavras(frase):', '    dic = {}', '    lista = frase.split()', '    for palavra in lista:', '        if palavra in dic:', '            dic[palavra] += 1', '        else:', '            dic[palavra] = 1', '    return dic']\n",
    "#gpt_tests = ['def test_intercala():\\n    assert intercala([1, 3, 5], [2, 4, 6]) == [1, 2, 3, 4, 5, 6]\\n', 'def test_intercala_2():\\n    assert intercala([7, 9, 11], [8, 10, 12]) == [7, 8, 9, 10, 11, 12]\\n', 'def test_intercala_3():\\n    assert intercala([0, 2, 4], [1, 3, 5]) == [0, 1, 2, 3, 4, 5]\\n']\n",
    "#function_lines = ['def intercala(lista1,lista2):', '    lista3 = 6*[0]', '    lista3[::2] = lista1', '    lista3[1::2] = lista2', '    return lista3']\n",
    "with open(file_name, 'w', encoding='utf-8') as file:\n",
    "    file.write(function_lines[0] + \"\\n\")\n",
    "    file.write(\" \" * 4 + \"with open(\\\"holder.txt\\\", \\\"a\\\") as file:\" + \"\\n\")\n",
    "    file.write(\" \" * 8 + \"file.write(\\\"\" + function_lines[0].strip().replace(\"def \", \"enter: \").replace(\"):\", \")\") + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "    for i in range(1, len(function_lines)):\n",
    "        if not \"else\" in function_lines[i]:\n",
    "            file.write(\" \" * 4 + \" \" * count_blank_spaces(function_lines[i]) + \"file.write(\\\"\" + function_lines[i].strip() + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "        if \"return\" in function_lines[i]:\n",
    "            file.write(\" \" * 8 + \"file.write(\\\"\" + function_lines[0].strip().replace(\"def \", \"exit: \").replace(\"):\", \")\") + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "        file.write(\" \" * 4 + function_lines[i] + \"\\n\")\n",
    "        if \"else\" in function_lines[i]:\n",
    "            file.write(\" \" * 8 + \" \" * count_blank_spaces(function_lines[i]) + \"file.write(\\\"\" + function_lines[i].strip() + \"\\\" + \\\"\\\\n\\\")\" + \"\\n\")\n",
    "    \n",
    "    file.write(\"\\n\")\n",
    "    for test in gpt_tests:\n",
    "        for line in test.split('\\n'):\n",
    "            file.write(line + \"\\n\")\n",
    "\n",
    "#remove_file(file_name)\n",
    "remove_all_files(\"__pycache__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enter: freq_palavras(frase)', 'dic = {}', 'lista = frase.split()', 'for palavra in lista:', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'dic[palavra] += 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'return dic', 'exit: freq_palavras(frase)']\n",
      "['enter: freq_palavras(frase)', 'dic = {}', 'lista = frase.split()', 'for palavra in lista:', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'return dic', 'exit: freq_palavras(frase)']\n",
      "['enter: freq_palavras(frase)', 'dic = {}', 'lista = frase.split()', 'for palavra in lista:', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'return dic', 'exit: freq_palavras(frase)']\n",
      "['enter: freq_palavras(frase)', 'dic = {}', 'lista = frase.split()', 'for palavra in lista:', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'return dic', 'exit: freq_palavras(frase)']\n",
      "['enter: freq_palavras(frase)', 'dic = {}', 'lista = frase.split()', 'for palavra in lista:', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'if palavra in dic:', 'else:', 'dic[palavra] = 1', 'return dic', 'exit: freq_palavras(frase)']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def freq_palavras(frase):\n",
    "    with open(\"holder.txt\", \"a\") as file:\n",
    "        file.write(\"enter: freq_palavras(frase)\" + \"\\n\")\n",
    "        file.write(\"dic = {}\" + \"\\n\")\n",
    "        dic = {}\n",
    "        file.write(\"lista = frase.split()\" + \"\\n\")\n",
    "        lista = frase.split()\n",
    "        file.write(\"for palavra in lista:\" + \"\\n\")\n",
    "        for palavra in lista:\n",
    "            file.write(\"if palavra in dic:\" + \"\\n\")\n",
    "            if palavra in dic:\n",
    "                file.write(\"dic[palavra] += 1\" + \"\\n\")\n",
    "                dic[palavra] += 1\n",
    "            else:\n",
    "                file.write(\"else:\" + \"\\n\")\n",
    "                file.write(\"dic[palavra] = 1\" + \"\\n\")\n",
    "                dic[palavra] = 1\n",
    "        file.write(\"return dic\" + \"\\n\")\n",
    "        file.write(\"exit: freq_palavras(frase)\" + \"\\n\")\n",
    "        return dic\n",
    "\n",
    "tests = []\n",
    "for line in gpt_tests:\n",
    "    pattern = r'assert (.*)'\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        matched_content = match.group(1)\n",
    "        tests.append(matched_content)\n",
    "\n",
    "for test in tests:\n",
    "    result = eval(test)\n",
    "    with open(\"holder.txt\", \"a\") as file:\n",
    "        file.write(\"test_delimiter\\n\")\n",
    "\n",
    "result = []  # The list of lists\n",
    "current_list = []  # The current list being populated\n",
    "\n",
    "with open(\"holder.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()  # Remove leading/trailing whitespace\n",
    "\n",
    "        if line == \"test_delimiter\":\n",
    "            if current_list:  # Check if the current_list is not empty\n",
    "                result.append(current_list)  # Add it to the result list\n",
    "            current_list = []  # Start a new current_list\n",
    "        else:\n",
    "            current_list.append(line)\n",
    "\n",
    "# Append the last list (if not empty) to the result\n",
    "if current_list:\n",
    "    result.append(current_list)\n",
    "\n",
    "for test in result:\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseGraph(cfg):\n",
    "    i = -1\n",
    "    nodes = []\n",
    "    for block in cfg:\n",
    "            current = []\n",
    "            neighbours = []\n",
    "            source = str(i) +\" : \"+ str(block.get_source())\n",
    "            source = source.strip(\"\\n\")\n",
    "            node = re.findall(\"\\d*@\", str(block))[0]\n",
    "            node = int(node[:-1])\n",
    "            if (node != \"1\"):\n",
    "                for e in block.exits:\n",
    "                    neighbour = re.findall(\"\\d*@\", str(e))[1]\n",
    "                    neighbour = int(neighbour[:-1])\n",
    "                    neighbours.append(neighbour)\n",
    "            current.append(i)\n",
    "            current.append(node)\n",
    "            current.append(neighbours)\n",
    "            current.append(source)\n",
    "            nodes.append(current)\n",
    "            i += 1\n",
    "\n",
    "    nodes.pop(0)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FormatGraph(nodes):\n",
    "\t\n",
    "\t#gera um dicionario que sera usado para substituir os valores do py2cfg por numeros em ordem crescente, \n",
    "    # o metodo do py2cfg corta nos nos redundantes, deixando referencias fantasmas no grafo original, necessitando essa limpeza da saida para podermos manipular\n",
    "\n",
    "    dict = {}\n",
    "    for node in nodes:\n",
    "        dict[node[1]] = node[0]\n",
    "\n",
    "    #substitui os nós vizinhos de cada nó usando o dicionario\n",
    "    for node in nodes:\n",
    "        for idx, neighbour in enumerate(node[2]):\n",
    "            node[2][idx] = dict[neighbour]\n",
    "\n",
    "    # remove o agora redundante valores antigos de index do py2cfg\n",
    "    for node in nodes:\n",
    "        node.pop(1)\n",
    "\n",
    "    # resultado final, uma lista de nós, contendo seus vizinhos e o tamanho do grafo\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GerarRequisitos(nodes):\n",
    "\t\n",
    "    R1, R2, R3 = [], [], []\n",
    "\n",
    "\t# gera primeira lista de requisitos de nós, percorendo a lista e registrando os nós existentes \n",
    "    for node in nodes:\n",
    "        R1.append(node[0])\n",
    "\n",
    "    # gera lista de requisitos de arcos, percorendo a lista e explorando os vizinhos\n",
    "    for node in nodes:\n",
    "        for idx, neighbour in enumerate(node[1]):\n",
    "            R2.append([node[0],node[1][idx]])\n",
    "\n",
    "    # gera lista de requisitos de par de arcos, percorendo a lista e explorando os vizinhos\n",
    "    for node in nodes:\n",
    "        for idx1, neighbour1 in enumerate(node[1]):\n",
    "            if len(nodes[neighbour1][1]) == 0:\n",
    "                if len(R3) == 0:\n",
    "                    R3.append([node[0],node[1][idx1]])\n",
    "            for idx2, neighbour2 in enumerate(nodes[neighbour1][1]):\n",
    "                R3.append([node[0],node[1][idx1],nodes[neighbour1][1][idx2]])\n",
    "\n",
    "    return [R1,R2,R3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreatePath(nodes, path, tests, requisitos, limit, depth):\n",
    "\t#caso de quebra onde profundidade passou do limite da recursividade\n",
    "\tif depth > limit:\n",
    "\t\treturn tests\n",
    "\t#caso inicial de um caminho vazio\n",
    "\tif path == []:\n",
    "\t\tfor element in nodes:\n",
    "\t\t\tif not element[1]:\n",
    "\t\t\t\tpath.insert(0, element[0])\n",
    "\t\t\t\tdepth = depth + 1\n",
    "\t\t\t\ttests = CreatePath(nodes, path, tests, requisitos, limit, depth)\n",
    "\t\t\t\tdepth = depth - 1\n",
    "\t\t\t\tpath.pop(0)\n",
    "\t#caso onde é encontrado o no inicial 0 do grafo, então é avaliado se o caminho esta completando algum requisito novo\n",
    "\telif path[0] == 0:\n",
    "\t\ti = 0\n",
    "\t\tnew = False\n",
    "\t\twhile i+2 < len(path):\n",
    "\t\t\trequisito = [path[i],path[i+1],path[i+2]]\n",
    "\t\t\tif requisito in requisitos:\n",
    "\t\t\t\tnew = True\n",
    "\t\t\t\trequisitos.remove(requisito)\n",
    "\t\t\ti += 1\n",
    "\t\tif len(path) == 2:\n",
    "\t\t\trequisito = [path[i],path[i+1]]\n",
    "\t\t\tif requisito in requisitos:\n",
    "\t\t\t\tnew = True\n",
    "\t\t\t\trequisitos.remove(requisito)\n",
    "\t\tif new:\n",
    "\t\t\ttests.append(path.copy())\n",
    "\t#caso aonde a raiz do grafo nao foi encontrado\n",
    "\telif path[0] != 0:\n",
    "\t\tfor element in nodes:\n",
    "\t\t\tif path[0] in element[1]:\n",
    "\t\t\t\tpath.insert(0, element[0])\n",
    "\t\t\t\tdepth = depth + 1\n",
    "\t\t\t\ttests = CreatePath(nodes, path, tests, requisitos, limit, depth)\n",
    "\t\t\t\tdepth = depth - 1\n",
    "\t\t\t\tpath.pop(0)\n",
    "\treturn tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SuggestTest(nodes, requisitos, limit):\n",
    "\trequisitosFaltantes = requisitos.copy()\n",
    "\trequisitosTestes = requisitos.copy()\n",
    "\ttests = []\n",
    "\tcompliance = []\n",
    "\t#busca criar caminhos coma  função createpatha te a lista de requisitos estar vazia, com um limite inicial \n",
    "\twhile requisitosTestes:\n",
    "\t\ttests = CreatePath(nodes, [], tests, requisitosTestes, limit, 0)\n",
    "\t\tlimit = limit+1\n",
    "\n",
    "\tfor test in tests:\n",
    "\t\t\tcompliancetemp = []\n",
    "\t\t\ti = 0\n",
    "\t\t\twhile i+2 < len(test):\n",
    "\t\t\t\trequisito = [test[i],test[i+1],test[i+2]]\n",
    "\t\t\t\tif requisito in requisitosFaltantes:\n",
    "\t\t\t\t\tcompliancetemp.append(requisito)\n",
    "\t\t\t\t\trequisitosFaltantes.remove(requisito)\n",
    "\t\t\t\ti += 1\n",
    "\t\t\tif len(test) == 2:\n",
    "\t\t\t\trequisito = [test[i],test[i+1]]\n",
    "\t\t\t\tif requisito in requisitosFaltantes:\n",
    "\t\t\t\t\tcompliancetemp.append(requisito)\n",
    "\t\t\t\t\trequisitosFaltantes.remove(requisito)\n",
    "\t\t\tcompliance.append(compliancetemp)\n",
    "\n",
    "\treturn tests, compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeradorDeRequisitos(filepath, filename):\n",
    "    cfg = CFGBuilder().build_from_file('example', filepath)\n",
    "    \n",
    "    nodes = FormatGraph(ParseGraph(cfg))\n",
    "    requisitos = GerarRequisitos(nodes)\n",
    "    requisitosTestes = requisitos.copy()\n",
    "    name = \"requisitos \" + filename +\".txt\" \n",
    "    testes, compliance = SuggestTest(nodes, requisitosTestes[2], 3)\n",
    "    requisitos[0] = \"requisitos de nós (\" + str(len(requisitos[0])) + \") : \" + str(requisitos[0])\n",
    "    requisitos[1] = \"requisitos de arcos (\" + str(len(requisitos[1])) + \") : \" + str(requisitos[1])\n",
    "    requisitos[2] = \"requisitos de par de arcos (\" + str(len(requisitos[2])) + \") : \" + str(requisitos[2])\n",
    "\n",
    "    testesPropostos = []\n",
    "    i = 0\n",
    "    for teste in testes:\n",
    "        testesPropostos.append(\"T\"+ str(i) + \": \" + str(teste))\n",
    "        i += 1\n",
    "\n",
    "    with open(name, 'w') as file:\n",
    "        file.write(str(requisitos[0]) + '\\n')\n",
    "        file.write(str(requisitos[1]) + '\\n')\n",
    "        file.write(str(requisitos[2]) + '\\n\\n\\n')\n",
    "\n",
    "        i = 0\n",
    "        for proposta in testesPropostos:\n",
    "            file.write(str(proposta) + '\\n')\n",
    "            file.write(str(compliance[i]) + '\\n\\n\\n')\n",
    "            i += 1\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_adjacent_duplicates(lst):\n",
    "    result = []\n",
    "    for i in range(len(lst)):\n",
    "        if i == 0 or lst[i] != lst[i - 1]:\n",
    "            result.append(lst[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minimal_tests(nodes, test_nodes):\n",
    "    covered_nodes = set()\n",
    "    minimal_tests = []\n",
    "\n",
    "    # Sort the test nodes by length in descending order\n",
    "    test_nodes.sort(key=len, reverse=True)\n",
    "\n",
    "    for i in range(len(test_nodes)):\n",
    "        # Check if any nodes in the current test node list are not covered\n",
    "        uncovered_nodes = [node for node in test_nodes[i] if node not in covered_nodes]\n",
    "        \n",
    "        if uncovered_nodes:\n",
    "            # If there are uncovered nodes in this test, add the test to minimal_tests\n",
    "            minimal_tests.append(i)\n",
    "            # Update the covered nodes\n",
    "            covered_nodes.update(uncovered_nodes)\n",
    "\n",
    "        if len(covered_nodes) == len(nodes):\n",
    "            # All nodes are covered, so we can stop\n",
    "            break\n",
    "\n",
    "    return minimal_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"problem_solution\"\n",
    "nodes = GeradorDeRequisitos(\"./\"+filename+\".py\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test_1():\n",
      "    assert freq_palavras(\"dinheiro é dinheiro e vice versa\") == {\"dinheiro\": 2, \"é\": 1, \"e\": 1, \"vice\": 1, \"versa\": 1}\n",
      "\n",
      "def test_2():\n",
      "    assert freq_palavras(\"o rato roeu a roupa do rei de roma\") == {\"o\": 2, \"rato\": 1, \"roeu\": 1, \"a\": 1, \"roupa\": 1, \"do\": 1, \"rei\": 1, \"de\": 1, \"roma\": 1}\n",
      "\n",
      "[[0, 1, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 3], [0, 1, 2, 5, 2, 5, 2, 4, 2, 5, 2, 5, 2, 5, 3], [0, 1, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 3], [0, 1, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 3], [0, 1, 2, 5, 2, 5, 2, 5, 2, 5, 3]]\n"
     ]
    }
   ],
   "source": [
    "test_nodes = []\n",
    "for test in result:\n",
    "    tests_n = []\n",
    "    for line in test:\n",
    "        for n in nodes:\n",
    "            if line.replace('\\n', '').replace(' ', '') in n[2].replace('\\n', '').replace(' ', ''):\n",
    "                tests_n.append(n[0])\n",
    "    test_nodes.append(remove_adjacent_duplicates(tests_n))\n",
    "\n",
    "all_nodes = [sublist[0] for sublist in nodes]\n",
    "minimal_tests = find_minimal_tests(all_nodes, test_nodes)\n",
    "filtered_list = [gpt_tests[i] for i in minimal_tests if i < len(gpt_tests)]\n",
    "for t in filtered_list:\n",
    "    print(t)\n",
    "\n",
    "print(test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test_1():\n",
      "    assert freq_palavras(\"dinheiro é dinheiro e vice versa\") == {\"dinheiro\": 2, \"é\": 1, \"e\": 1, \"vice\": 1, \"versa\": 1}\n",
      "\n",
      "def test_2():\n",
      "    assert freq_palavras(\"o rato roeu a roupa do rei de roma\") == {\"o\": 2, \"rato\": 1, \"roeu\": 1, \"a\": 1, \"roupa\": 1, \"do\": 1, \"rei\": 1, \"de\": 1, \"roma\": 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_edges, test_edges = [], []\n",
    "for node in nodes:\n",
    "        for idx, neighbour in enumerate(node[1]):\n",
    "            all_edges.append(tuple([node[0],node[1][idx]]))\n",
    "\n",
    "test_edges, current_test_edges = [], []\n",
    "for test in test_nodes:\n",
    "    for i in range(len(test) - 1):\n",
    "        current_test_edges.append(tuple([test[i], test[i+1]]))\n",
    "    test_edges.append(current_test_edges)\n",
    "    current_test_edges = []\n",
    "\n",
    "minimal_edge_tests = find_minimal_tests(all_edges, test_edges)\n",
    "filtered_list = [gpt_tests[i] for i in minimal_tests if i < len(gpt_tests)]\n",
    "for t in filtered_list:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test_1():\n",
      "    assert freq_palavras(\"dinheiro é dinheiro e vice versa\") == {\"dinheiro\": 2, \"é\": 1, \"e\": 1, \"vice\": 1, \"versa\": 1}\n",
      "\n",
      "def test_2():\n",
      "    assert freq_palavras(\"o rato roeu a roupa do rei de roma\") == {\"o\": 2, \"rato\": 1, \"roeu\": 1, \"a\": 1, \"roupa\": 1, \"do\": 1, \"rei\": 1, \"de\": 1, \"roma\": 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_pairs, tests_pair_edges = [], []\n",
    "with open(\"requisitos \" + filename + \".txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        if \"par de arcos\" in line:\n",
    "            all_pairs = line[line.index(\":\") + 1:].strip()\n",
    "\n",
    "for tn in test_nodes:\n",
    "    pairs, current_pair, unique_pairs, test_pair_edge = [], [], [], []\n",
    "    for node in tn:\n",
    "        current_pair.append(node)\n",
    "        if (len(current_pair) == 3):\n",
    "            pairs.append(current_pair)\n",
    "            current_pair = current_pair[1:]\n",
    "\n",
    "    for sublist in pairs:\n",
    "        if sublist not in unique_pairs:\n",
    "            unique_pairs.append(sublist)\n",
    "\n",
    "    for sublist in unique_pairs:\n",
    "        test_pair_edge.append(tuple(sublist))\n",
    "\n",
    "    tests_pair_edges.append(test_pair_edge)\n",
    "\n",
    "minimal_edge_tests = find_minimal_tests(all_pairs, tests_pair_edges)\n",
    "filtered_list = [gpt_tests[i] for i in minimal_tests if i < len(gpt_tests)]\n",
    "for t in filtered_list:\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
